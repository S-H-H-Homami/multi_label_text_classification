{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/S-H-H-Homami/multi_label_text_classification/blob/main/multi_label_text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-label text classification\n",
        "\n",
        "**Author:** [Farrokh Karimi](https://farrokhkarimi.github.io/)  \n",
        "**Description:** In this notebook, we want to classify the Ronash dataset into 20 category."
      ],
      "metadata": {
        "id": "Bij91pNWQOR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import tensorflow as tf\n",
        "\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "sL739kMAEsU9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# downloading Data from the Google Drive link\n",
        "!gdown 1Yq3XTnACkvaIiNlhX09Zth55nOau7jQy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHa9m3aLEbyP",
        "outputId": "19c2acb2-2686-49ea-b8b7-257a8c3a078e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Yq3XTnACkvaIiNlhX09Zth55nOau7jQy\n",
            "To: /content/Ronash_DS_Assignment.csv\n",
            "\r  0% 0.00/1.05M [00:00<?, ?B/s]\r100% 1.05M/1.05M [00:00<00:00, 165MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QpBuoWrC5QS",
        "outputId": "e6cfa161-b936-4de7-9192-684bb5f25590"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ronash_DS_Assignment.csv  \u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reading the csv file as a dataframe\n",
        "df = pd.read_csv('Ronash_DS_Assignment.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "722bMOmzF4_H",
        "outputId": "ee3f9b5e-818e-4d3b-95b1-7000b33fa9f4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         product_id                                              title  \\\n",
              "0     3937721221199    Fidele Super Premium Adult Large Breed Dog Food   \n",
              "1     7353058033889                    Foldable Pet Toys Linen Storage   \n",
              "2     6594773549129                                     Bok Dok Diaper   \n",
              "3     4802008318014                              Tastybone Toy Chicken   \n",
              "4     1779705151539                Leather Leash Tab - Short Dog Leash   \n",
              "...             ...                                                ...   \n",
              "5265  4637089464407                              Candylab MOO Milk Van   \n",
              "5266  4996632444987  Truck - Modern Era Vehicles -- Red, White -  S...   \n",
              "5267  5528541003927  Car Sticker Flags Decal American Flag Sticker for   \n",
              "5268  1395163889730          Lazer Helmets Bayamo Pit Bull - Full Face   \n",
              "5269  3535679324240                             Deutz Agrotron Tractor   \n",
              "\n",
              "                 vendor                                               tags  \\\n",
              "0                Fidele  ['Adult', 'Bangalore', 'Chennai', 'Chicken', '...   \n",
              "1             Cap Point                                                 []   \n",
              "2             Pets Home  ['Brand_Pet Arabia', 'Category_Pets Home', 'Ca...   \n",
              "3             TastyBone                                                 []   \n",
              "4            Mighty Paw                 ['Leash', 'Leash Tab', 'Training']   \n",
              "...                 ...                                                ...   \n",
              "5265           Candylab  ['3 Years +', 'candylab', 'Discount Products',...   \n",
              "5266   Woodland Scenics  ['HO Scale', 'ho-scale-items', 'vehicles', 'wo...   \n",
              "5267        Cyan Selene                                          ['Other']   \n",
              "5268  OPEN BOX BARGAINS  ['65061090', 'Antiscratch Pinlock Ready Visor'...   \n",
              "5269               Siku  ['$0 to $25', 'diecast-models', 'gift-finder',...   \n",
              "\n",
              "                    category  \n",
              "0     Animals & Pet Supplies  \n",
              "1     Animals & Pet Supplies  \n",
              "2     Animals & Pet Supplies  \n",
              "3     Animals & Pet Supplies  \n",
              "4     Animals & Pet Supplies  \n",
              "...                      ...  \n",
              "5265        Vehicles & Parts  \n",
              "5266        Vehicles & Parts  \n",
              "5267        Vehicles & Parts  \n",
              "5268        Vehicles & Parts  \n",
              "5269        Vehicles & Parts  \n",
              "\n",
              "[5270 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5d1d5d63-2492-42f1-8a5d-a7393e136308\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_id</th>\n",
              "      <th>title</th>\n",
              "      <th>vendor</th>\n",
              "      <th>tags</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3937721221199</td>\n",
              "      <td>Fidele Super Premium Adult Large Breed Dog Food</td>\n",
              "      <td>Fidele</td>\n",
              "      <td>['Adult', 'Bangalore', 'Chennai', 'Chicken', '...</td>\n",
              "      <td>Animals &amp; Pet Supplies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7353058033889</td>\n",
              "      <td>Foldable Pet Toys Linen Storage</td>\n",
              "      <td>Cap Point</td>\n",
              "      <td>[]</td>\n",
              "      <td>Animals &amp; Pet Supplies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6594773549129</td>\n",
              "      <td>Bok Dok Diaper</td>\n",
              "      <td>Pets Home</td>\n",
              "      <td>['Brand_Pet Arabia', 'Category_Pets Home', 'Ca...</td>\n",
              "      <td>Animals &amp; Pet Supplies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4802008318014</td>\n",
              "      <td>Tastybone Toy Chicken</td>\n",
              "      <td>TastyBone</td>\n",
              "      <td>[]</td>\n",
              "      <td>Animals &amp; Pet Supplies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1779705151539</td>\n",
              "      <td>Leather Leash Tab - Short Dog Leash</td>\n",
              "      <td>Mighty Paw</td>\n",
              "      <td>['Leash', 'Leash Tab', 'Training']</td>\n",
              "      <td>Animals &amp; Pet Supplies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5265</th>\n",
              "      <td>4637089464407</td>\n",
              "      <td>Candylab MOO Milk Van</td>\n",
              "      <td>Candylab</td>\n",
              "      <td>['3 Years +', 'candylab', 'Discount Products',...</td>\n",
              "      <td>Vehicles &amp; Parts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5266</th>\n",
              "      <td>4996632444987</td>\n",
              "      <td>Truck - Modern Era Vehicles -- Red, White -  S...</td>\n",
              "      <td>Woodland Scenics</td>\n",
              "      <td>['HO Scale', 'ho-scale-items', 'vehicles', 'wo...</td>\n",
              "      <td>Vehicles &amp; Parts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5267</th>\n",
              "      <td>5528541003927</td>\n",
              "      <td>Car Sticker Flags Decal American Flag Sticker for</td>\n",
              "      <td>Cyan Selene</td>\n",
              "      <td>['Other']</td>\n",
              "      <td>Vehicles &amp; Parts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5268</th>\n",
              "      <td>1395163889730</td>\n",
              "      <td>Lazer Helmets Bayamo Pit Bull - Full Face</td>\n",
              "      <td>OPEN BOX BARGAINS</td>\n",
              "      <td>['65061090', 'Antiscratch Pinlock Ready Visor'...</td>\n",
              "      <td>Vehicles &amp; Parts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5269</th>\n",
              "      <td>3535679324240</td>\n",
              "      <td>Deutz Agrotron Tractor</td>\n",
              "      <td>Siku</td>\n",
              "      <td>['$0 to $25', 'diecast-models', 'gift-finder',...</td>\n",
              "      <td>Vehicles &amp; Parts</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5270 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5d1d5d63-2492-42f1-8a5d-a7393e136308')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5d1d5d63-2492-42f1-8a5d-a7393e136308 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5d1d5d63-2492-42f1-8a5d-a7393e136308');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# counting the number of each label\n",
        "df['category'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6E1ZDXyPlr6y",
        "outputId": "aa8ca9ba-2891-42d9-9be1-97cf493701fa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Apparel & Accessories        1000\n",
              "Animals & Pet Supplies        500\n",
              "Food, Beverages & Tobacco     400\n",
              "Sporting Goods                400\n",
              "Luggage & Bags                400\n",
              "Home & Garden                 400\n",
              "Health & Beauty               400\n",
              "Media                         300\n",
              "Toys & Games                  300\n",
              "Furniture                     200\n",
              "Baby & Toddler                200\n",
              "Arts & Entertainment          200\n",
              "Electronics                   100\n",
              "Business & Industrial         100\n",
              "Office Supplies               100\n",
              "Vehicles & Parts              100\n",
              "Hardware                       50\n",
              "Cameras & Optics               50\n",
              "Software                       50\n",
              "Religious & Ceremonial         20\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# counting how many indices are duplicated in each column\n",
        "print(f\"There are {sum(df['title'].duplicated())} duplicate title.\")\n",
        "print(f\"There are {sum(df['vendor'].duplicated())} duplicate vondor.\")\n",
        "print(f\"There are {sum(df['tags'].duplicated())} duplicate tags.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Un_ggKoLUAEf",
        "outputId": "7eb6dec8-4b6d-482a-b59f-34ec54496096"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 0 duplicate title.\n",
            "There are 1256 duplicate vondor.\n",
            "There are 716 duplicate tags.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# counting the number of Nan samples\n",
        "df.isnull().values.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VD95efZwCRYT",
        "outputId": "ff201768-a0b3-487d-bd63-8b6985f2da14"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are just 3 Nan samples in the dataset so we can ignore them."
      ],
      "metadata": {
        "id": "rhPJQuDEb8oN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the function for extracting and standardizing the sentences\n",
        "def text_extraction(dfi):\n",
        "  # in this function, we concatenate text feature parts of the data as a sentence\n",
        "  sentence = ' '.join([dfi['title'], str(dfi['vendor']), dfi['tags']])\n",
        "  # Remove punctuations\n",
        "  sentence = re.sub('[^a-zA-Z0-9$.]', ' ', sentence)\n",
        "  # Single character removal\n",
        "  sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
        "  # Removing multiple spaces\n",
        "  sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "  # Changint to lowercase\n",
        "  sentence = sentence.lower()\n",
        "  return sentence\n",
        "\n",
        "# printing 10 sample sentences\n",
        "for i in range(10):\n",
        "  print(text_extraction(df.iloc[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aH9UzP7-__P2",
        "outputId": "bed42f35-a9ef-4924-da0c-9e499945f196"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fidele super premium adult large breed dog food fidele adult bangalore chennai chicken doberman dog dry foods fidele german shepherd golden retriever great dane highpriority imported labrador less than 1000 less than 2000 less than 500 mastiff orange pet nutrition \n",
            "foldable pet toys linen storage cap point \n",
            "bok dok diaper pets home brand pet arabia category pets home category small pets supplies type pet home type pet supplies \n",
            "tastybone toy chicken tastybone \n",
            "leather leash tab short dog leash mighty paw leash leash tab training \n",
            "pridebites texas guitar dog toy pride bites brand pridebites toy type plush \n",
            "burns sensitive pork potato burns 10 25 25 50 50 75 adult burns coat dog food food delivery jansale18 natural nonsale19 sensitive size 12kg size 2kg size 6kg skin \n",
            "bully sticks dog toy adog.co bully sticks dog chew toys dog toys \n",
            "kazoo tough giraffe dog toy kazoo brand kazoo june2021 kazoo material plush plush \n",
            "orgo dog biscuits fresh milk petku brand orgo category dogs dogs lifestage all lifestages orgo price rp 0 to rp 100.000 subcategory treats treats \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating the dataset\n",
        "dataset = pd.DataFrame(columns=['text', 'label'])\n",
        "for i in range(len(df)):\n",
        "  dataset = dataset.append({'text':text_extraction(df.iloc[i]), 'label':df.iloc[i]['category']}, ignore_index = True)\n",
        "\n",
        "# creating integer labels for multiclass training\n",
        "dataset['label_int'] = pd.Categorical(dataset['label']).codes\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "7x4WG7NC9Xz3",
        "outputId": "8b789b69-dade-4b80-b3b3-4e6582a7ef60"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  \\\n",
              "0     fidele super premium adult large breed dog foo...   \n",
              "1            foldable pet toys linen storage cap point    \n",
              "2     bok dok diaper pets home brand pet arabia cate...   \n",
              "3                      tastybone toy chicken tastybone    \n",
              "4     leather leash tab short dog leash mighty paw l...   \n",
              "...                                                 ...   \n",
              "5265  candylab moo milk van candylab 3 years candyla...   \n",
              "5266  truck modern era vehicles red white scale ho w...   \n",
              "5267  car sticker flags decal american flag sticker ...   \n",
              "5268  lazer helmets bayamo pit bull full face open b...   \n",
              "5269  deutz agrotron tractor siku $0 to $25 diecast ...   \n",
              "\n",
              "                       label  label_int  \n",
              "0     Animals & Pet Supplies          0  \n",
              "1     Animals & Pet Supplies          0  \n",
              "2     Animals & Pet Supplies          0  \n",
              "3     Animals & Pet Supplies          0  \n",
              "4     Animals & Pet Supplies          0  \n",
              "...                      ...        ...  \n",
              "5265        Vehicles & Parts         19  \n",
              "5266        Vehicles & Parts         19  \n",
              "5267        Vehicles & Parts         19  \n",
              "5268        Vehicles & Parts         19  \n",
              "5269        Vehicles & Parts         19  \n",
              "\n",
              "[5270 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9ae51cc1-5efa-44b7-b089-1524def2a7a3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>label_int</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>fidele super premium adult large breed dog foo...</td>\n",
              "      <td>Animals &amp; Pet Supplies</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>foldable pet toys linen storage cap point</td>\n",
              "      <td>Animals &amp; Pet Supplies</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bok dok diaper pets home brand pet arabia cate...</td>\n",
              "      <td>Animals &amp; Pet Supplies</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tastybone toy chicken tastybone</td>\n",
              "      <td>Animals &amp; Pet Supplies</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>leather leash tab short dog leash mighty paw l...</td>\n",
              "      <td>Animals &amp; Pet Supplies</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5265</th>\n",
              "      <td>candylab moo milk van candylab 3 years candyla...</td>\n",
              "      <td>Vehicles &amp; Parts</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5266</th>\n",
              "      <td>truck modern era vehicles red white scale ho w...</td>\n",
              "      <td>Vehicles &amp; Parts</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5267</th>\n",
              "      <td>car sticker flags decal american flag sticker ...</td>\n",
              "      <td>Vehicles &amp; Parts</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5268</th>\n",
              "      <td>lazer helmets bayamo pit bull full face open b...</td>\n",
              "      <td>Vehicles &amp; Parts</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5269</th>\n",
              "      <td>deutz agrotron tractor siku $0 to $25 diecast ...</td>\n",
              "      <td>Vehicles &amp; Parts</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5270 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ae51cc1-5efa-44b7-b089-1524def2a7a3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9ae51cc1-5efa-44b7-b089-1524def2a7a3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9ae51cc1-5efa-44b7-b089-1524def2a7a3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting the names of the labels\n",
        "labels_names = list(Counter(dataset['label']).keys())\n",
        "labels_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uHdTY3p9Xfr",
        "outputId": "88247f9e-e34b-44e6-d40c-468ee124c2cc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Animals & Pet Supplies',\n",
              " 'Apparel & Accessories',\n",
              " 'Arts & Entertainment',\n",
              " 'Baby & Toddler',\n",
              " 'Business & Industrial',\n",
              " 'Cameras & Optics',\n",
              " 'Electronics',\n",
              " 'Food, Beverages & Tobacco',\n",
              " 'Furniture',\n",
              " 'Hardware',\n",
              " 'Health & Beauty',\n",
              " 'Home & Garden',\n",
              " 'Luggage & Bags',\n",
              " 'Media',\n",
              " 'Office Supplies',\n",
              " 'Religious & Ceremonial',\n",
              " 'Software',\n",
              " 'Sporting Goods',\n",
              " 'Toys & Games',\n",
              " 'Vehicles & Parts']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# printing each integer label and its corresponding name label\n",
        "for i, label in enumerate(labels_names):\n",
        "  print(\"Label\", i, \"corresponds to\", label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXCgd6QTC_k6",
        "outputId": "05044b57-0836-4295-9dd7-ca0453a0dfd8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label 0 corresponds to Animals & Pet Supplies\n",
            "Label 1 corresponds to Apparel & Accessories\n",
            "Label 2 corresponds to Arts & Entertainment\n",
            "Label 3 corresponds to Baby & Toddler\n",
            "Label 4 corresponds to Business & Industrial\n",
            "Label 5 corresponds to Cameras & Optics\n",
            "Label 6 corresponds to Electronics\n",
            "Label 7 corresponds to Food, Beverages & Tobacco\n",
            "Label 8 corresponds to Furniture\n",
            "Label 9 corresponds to Hardware\n",
            "Label 10 corresponds to Health & Beauty\n",
            "Label 11 corresponds to Home & Garden\n",
            "Label 12 corresponds to Luggage & Bags\n",
            "Label 13 corresponds to Media\n",
            "Label 14 corresponds to Office Supplies\n",
            "Label 15 corresponds to Religious & Ceremonial\n",
            "Label 16 corresponds to Software\n",
            "Label 17 corresponds to Sporting Goods\n",
            "Label 18 corresponds to Toys & Games\n",
            "Label 19 corresponds to Vehicles & Parts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting dataset to train, validation, and test dataframes\n",
        "train_df, test_df= train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "val_df = test_df.sample(frac=0.5)\n",
        "test_df.drop(val_df.index, inplace=True)\n",
        "\n",
        "print(f\"Number of samples in training set: {len(train_df)}\")\n",
        "print(f\"Number of samples in validation set: {len(val_df)}\")\n",
        "print(f\"Number of samples in test set: {len(test_df)}\")\n",
        "\n",
        "# extracting texts and labels from dataframes\n",
        "train_texts = train_df['text']\n",
        "train_labels = train_df['label_int']\n",
        "val_texts = val_df['text']\n",
        "val_labels = val_df['label_int']\n",
        "test_texts = test_df['text']\n",
        "test_labels = test_df['label_int']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWd2Rfp69X8g",
        "outputId": "597231fa-7a2b-4dc2-9030-0f328eaaa9cb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples in training set: 4216\n",
            "Number of samples in validation set: 527\n",
            "Number of samples in test set: 527\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating data generators with batch size 32\n",
        "batch_size = 32\n",
        "raw_train_batch = tf.data.Dataset.from_tensor_slices((train_texts, train_labels)).batch(batch_size)\n",
        "raw_val_batch = tf.data.Dataset.from_tensor_slices((val_texts, val_labels)).batch(batch_size)\n",
        "raw_test_batch = tf.data.Dataset.from_tensor_slices((test_texts, test_labels)).batch(batch_size)\n",
        "\n",
        "# printing texts and labels of a batch of raw train\n",
        "for text, label in raw_train_batch.take(1):\n",
        "  print('Texts: {}'.format(text))\n",
        "  print('labels: {}'.format(label))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4kA4X60zkC3",
        "outputId": "1fc40e99-0415-49ab-c25c-f5b3bedfc0f7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texts: [b'housie tambola game by brands with foldable reusable tickets snooplay 13 17 year olds 18 years above 251 500 8 12 year olds age no bar all time favourite below 1000 below 400 below 500 best selling board games creative games gifts customer favourites diwali family friends night family games friends family nights geek gifts for boys gifts for friends gifts for girls gifts for kids gifts for parents googleshopping nerd or geek new new collection outdoor games party accessories party essentials party freak party games party games for grown ups party games for kids premium unique new toys '\n",
            " b'foldable waterproof raised dog bed dogiti '\n",
            " b'quadrello di bufala cheese cut wrapped by igourmet category cheese cut cheeses milk type buffalo nutrition full set origin italy shipping perishable texture semi soft type stinky and washed rind wholesale cheese collection '\n",
            " b'quay vip pink navy to pink lens quay accessories new summer sunglasses '\n",
            " b'seachem multitest ammonia seachem '\n",
            " b'smart electric cat teasing toy pet clever cat toys cats rr track catproducts rr track cattoys '\n",
            " b'petroleum mixture sign the sign shed black text chemical chemical signs flammable signs general hazard portrait yellow bg '\n",
            " b'scott kingery andrew mccutchen philadelphia phillies ring the bell dual bobblehead foco data athlete andrew mccutchen data athlete scott kingery data city philadelphia data edition exclusive data filter collection no data filter discount yes data league mlb data region pennsylvania data sub category1 bobbleheads data team philadelphia phillies '\n",
            " b'diy personalised dreamcatcher activity kit sea animal doxbox store '\n",
            " b'dainty corduroy bow in lilac sweet first love bow corduroy headband purple spo disabled wos '\n",
            " b'new bts stylish backpack the pocket store '\n",
            " b'planet bike big buck fat front planet bike bicycle fenders bike accessories bikes fenders front fenders full price planet bike unisex '\n",
            " b'ms. better trans canada bitters enterprises jesemi inc. betters canada ms trans '\n",
            " b'drawstring backpack pink zig zag yoobi 10 15 2020 primedaydeal accessories all bags flair back to school backpacks bags bf2019 book bag book bags bookbag bookbags newyear pink pink zig zag sale summer2020 supplybundle zig zags '\n",
            " b'pineapple mini food speaker magnum brands add on birthday gift girl music pos speaker '\n",
            " b'interactive iq treat ball toy for dogs cats cj feeder waterer pet supplies '\n",
            " b'whisper of lord ganesha tarot deck u.s. games '\n",
            " b'handcrafted aasha cuff bracelet colorful cuff bracelet made with wooden beads wrapped with recycled sari fabrics. aasha bracelet comfy fair trade handcrafted handmade jewelry '\n",
            " b'idrop belik facial anti aging wrinkle ultrasonic face massager toothbrush attachment idrop anti aging anti wrinkle electric massager face massage facial massager health health beauty health fitness health care healthcare healthy healthy massager massage massager new ultrasonic '\n",
            " b'wood nativity puzzle mud pie one coas 10760023 baby children christmas gift god jesus kid religion toy '\n",
            " b'p.l.a.y. zoomierex fantastug sea foam dog toy p.l.a.y. brand p.l.a.y. summer collection toy type fetch toy type floating toy type rubber toy type tug twr '\n",
            " b'wallis simpson signed autobiography paul fraser collectibles autographs '\n",
            " b'imperial earring daya jewelry brass flower gold imperial spo default spo disabled spo enabled star tribal '\n",
            " b'armadillo nest charcoal armadillo alfresco armadillo door mats down to earth floor homeware homeware rugs mats labour weekend living modern boho rug rugs mats '\n",
            " b'millie pillow foreside pillows textiles '\n",
            " b'jelly brush aprilskin.us all '\n",
            " b'alarm you re little bitch blue blue blue crew cute exclude feed agegroup adult feed cl0 regularprice womens sassy funny words inappropriate cute profanity swear words exclude rude crude feed color blue feed cond new feed gender feed gender female feed gpc 209 funny inappropriate print profanity red regularprice rude crude sassy socks swear words womens words '\n",
            " b'boutique de paris lashes4today glamorous lashes luxury '\n",
            " b'dog pakiet dnp pc skin support pick me pets brand dolina noteci category pet supplies type dog food '\n",
            " b'plaza weekend diaper bag 7am label final sale addswatchrow adult age adult category diaper bags category weekenders color black color grey diaper diaper diaper ba dipper style plaza bag voyage '\n",
            " b'water sterling silver necklace wear the peace 925 sterling silver all products necklaces new arrivals '\n",
            " b'bain ultra violet rastase adha2020 adjusted assaad back in stock items bahaa black friday 2020 enabled blond absolu blondabsolu ramadan21 btpcat main 132768825422 btpcat other 132768825422 elian dada fadia el mendelek for colored blond hair hair care haircare summerfiesta sale jan 4 2021 price increase july 28th updated july increase ker aprist1st 2021 increase ker august 2021 price increase ker march 1st 2021 price increase ker priceincrease june1st 2021 kerastase ramadan21 rastase loolia2y mahmoud al zarif michel zeytoun non solar october 1st 2020 price increase or or reviews ppd price decrease 16th september 2021 ppd price decrease sept 2021 ppd price increase october1st 2021 ppd pricedecrease midseptember2021 ppd priceincrease 12th october 2021 price updated shampoos shant tawetian shop all stockcount 31 03 2021 weekend summerfiesta sale ']\n",
            "labels: [18  0  7  1  0  0  4  2  0  1 12 17  7 12 18  0 15  1 10 18  0  2  1 11\n",
            "  2  9  1 10  0 12  1 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# counting how many words are there in the whole texts of the dataset\n",
        "num_of_words = 0\n",
        "for i in dataset['text']: num_of_words += len(i.split())\n",
        "\n",
        "print(num_of_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2QpUriFrsU_",
        "outputId": "f1bb9ca5-a492-48d0-a85e-b2c27362c63f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "112572\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are about 112000 words in the texts.\n",
        "\n"
      ],
      "metadata": {
        "id": "wfw3CqfZsWyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# counting max sequence length and how many non-repetitive words are there in the whole texts of the dataset\n",
        "l = []\n",
        "max_seq_lenght = 0\n",
        "for i in dataset['text']:\n",
        "  lenght = len(i.split())\n",
        "  if lenght > max_seq_lenght: max_seq_lenght = lenght\n",
        "  for j in i.split():\n",
        "    if j not in l: l.append(j)\n",
        "\n",
        "print(max_seq_lenght)\n",
        "print(len(l))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ufQzaF9ncqZ",
        "outputId": "6bdd3845-d4f6-4634-d35f-5979d02a30ae"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "309\n",
            "18933\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maximum sequence length is 309 and There are about 19000 non-repetitive words in the whole dataset texts. So we set max word features to 10000 and sequence length to 350."
      ],
      "metadata": {
        "id": "cGGf8rQorkSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setting the text vectorization layer with 10000 words and 350 sequence length\n",
        "max_features = len(l)\n",
        "sequence_length = max_seq_lenght\n",
        "\n",
        "vectorize_layer = layers.TextVectorization(\n",
        "    max_tokens=max_features,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=sequence_length)\n",
        "\n",
        "# fitting the state of the preprocessing layer to the train set. This will cause the model to build an index of strings to integers.\n",
        "vectorize_layer.adapt(train_texts)\n",
        "\n",
        "# defining the vectorize text function\n",
        "def vectorize_text(text, label):\n",
        "  text = tf.expand_dims(text, -1)\n",
        "  return vectorize_layer(text), label\n",
        "\n",
        "# retrieving a sample from a batch of texts and labels from the train set\n",
        "text_batch, label_batch = next(iter(raw_train_batch))\n",
        "first_review, first_label = text_batch[0], label_batch[0]\n",
        "print(\"Review\", first_review)\n",
        "print(\"Label\", first_label)\n",
        "print(\"Vectorized text\", vectorize_text(first_review, first_label))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ey2QJjO97T9P",
        "outputId": "570e3827-9bd1-4a18-d221-ce6f3acf17e0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review tf.Tensor(b'housie tambola game by brands with foldable reusable tickets snooplay 13 17 year olds 18 years above 251 500 8 12 year olds age no bar all time favourite below 1000 below 400 below 500 best selling board games creative games gifts customer favourites diwali family friends night family games friends family nights geek gifts for boys gifts for friends gifts for girls gifts for kids gifts for parents googleshopping nerd or geek new new collection outdoor games party accessories party essentials party freak party games party games for grown ups party games for kids premium unique new toys ', shape=(), dtype=string)\n",
            "Label tf.Tensor(18, shape=(), dtype=int8)\n",
            "Vectorized text (<tf.Tensor: shape=(1, 309), dtype=int64, numpy=\n",
            "array([[12501,  9229,   192,    23,   343,    51,  1546,  2392,  9089,\n",
            "         9635,   740,  1609,   275,  2882,   372,    69,   959, 15878,\n",
            "          134,   109,    89,   275,  2882,    35,    55,   381,    16,\n",
            "          480,  7346,   783,   181,   783,   961,   783,   134,    79,\n",
            "         2792,   104,    57,  1195,    57,    53,  3072, 13287,  5047,\n",
            "          237,  1078,   716,   237,    57,  1078,   237,  6529,  4896,\n",
            "           53,    13,   334,    53,    13,  1078,    53,    13,   179,\n",
            "           53,    13,    62,    53,    13,  3473, 12859, 11174,   303,\n",
            "         4896,     3,     3,     8,   157,    57,   250,    17,   250,\n",
            "          316,   250,  7261,   250,    57,   250,    57,    13,  1904,\n",
            "         5674,   250,    57,    13,    62,   360,   632,     3,     6,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0]])>, <tf.Tensor: shape=(), dtype=int8, numpy=18>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# getting corresponding word of each integer \n",
        "print(\"1401 ---> \",vectorize_layer.get_vocabulary()[1401])\n",
        "print(\" 313 ---> \",vectorize_layer.get_vocabulary()[313])\n",
        "print('Vocabulary size: {}'.format(len(vectorize_layer.get_vocabulary())))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X84dkB768GSx",
        "outputId": "f2b12861-1054-43ff-f761-1c3207b2ff07"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1401 --->  heel\n",
            " 313 --->  is\n",
            "Vocabulary size: 16230\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating train, val, and test vectorized dataset and prefetching them\n",
        "train_ds = raw_train_batch.map(vectorize_text)\n",
        "val_ds = raw_val_batch.map(vectorize_text)\n",
        "test_ds = raw_test_batch.map(vectorize_text)\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "DiW717GQ_77D"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model configuration\n",
        "embedding_dim = 32\n",
        "num_of_labels = 20\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  layers.Embedding(max_features + 1, embedding_dim),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.GlobalAveragePooling1D(),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Dense(num_of_labels, activation= 'softmax')])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBHmGG_SAWhp",
        "outputId": "b232382c-08e3-4e79-e380-e59bb40843aa"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 32)          605888    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, None, 32)          0         \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 32)               0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 20)                660       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 606,548\n",
            "Trainable params: 606,548\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model compilation\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "uL6c-YGfAwLz"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training the model\n",
        "epochs = 500\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                            patience=30,\n",
        "                                            verbose=1)\n",
        "\n",
        "history = model.fit(train_ds,\n",
        "                    validation_data=val_ds,\n",
        "                    epochs=epochs,\n",
        "                    callbacks=[callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIfmPA3SvX4d",
        "outputId": "72b8b605-96ec-425e-beb6-b71775bdf913"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/backend.py:5585: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "132/132 [==============================] - 20s 142ms/step - loss: 2.8838 - accuracy: 0.1748 - val_loss: 2.7510 - val_accuracy: 0.1992\n",
            "Epoch 2/500\n",
            "132/132 [==============================] - 1s 6ms/step - loss: 2.7035 - accuracy: 0.1881 - val_loss: 2.6636 - val_accuracy: 0.1992\n",
            "Epoch 3/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 2.6752 - accuracy: 0.1881 - val_loss: 2.6488 - val_accuracy: 0.1992\n",
            "Epoch 4/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 2.6627 - accuracy: 0.1881 - val_loss: 2.6399 - val_accuracy: 0.1992\n",
            "Epoch 5/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 2.6592 - accuracy: 0.1881 - val_loss: 2.6322 - val_accuracy: 0.1992\n",
            "Epoch 6/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 2.6501 - accuracy: 0.1881 - val_loss: 2.6248 - val_accuracy: 0.1992\n",
            "Epoch 7/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 2.6439 - accuracy: 0.1886 - val_loss: 2.6168 - val_accuracy: 0.1992\n",
            "Epoch 8/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 2.6312 - accuracy: 0.1883 - val_loss: 2.6078 - val_accuracy: 0.2011\n",
            "Epoch 9/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 2.6207 - accuracy: 0.1895 - val_loss: 2.5975 - val_accuracy: 0.2011\n",
            "Epoch 10/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 2.6069 - accuracy: 0.1902 - val_loss: 2.5860 - val_accuracy: 0.2011\n",
            "Epoch 11/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 2.5939 - accuracy: 0.1945 - val_loss: 2.5730 - val_accuracy: 0.2030\n",
            "Epoch 12/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 2.5770 - accuracy: 0.1985 - val_loss: 2.5585 - val_accuracy: 0.2049\n",
            "Epoch 13/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 2.5591 - accuracy: 0.2047 - val_loss: 2.5428 - val_accuracy: 0.2087\n",
            "Epoch 14/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 2.5392 - accuracy: 0.2083 - val_loss: 2.5250 - val_accuracy: 0.2106\n",
            "Epoch 15/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 2.5201 - accuracy: 0.2194 - val_loss: 2.5058 - val_accuracy: 0.2334\n",
            "Epoch 16/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 2.4920 - accuracy: 0.2270 - val_loss: 2.4844 - val_accuracy: 0.2353\n",
            "Epoch 17/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 2.4699 - accuracy: 0.2327 - val_loss: 2.4621 - val_accuracy: 0.2391\n",
            "Epoch 18/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 2.4375 - accuracy: 0.2467 - val_loss: 2.4366 - val_accuracy: 0.2524\n",
            "Epoch 19/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 2.4117 - accuracy: 0.2538 - val_loss: 2.4120 - val_accuracy: 0.2657\n",
            "Epoch 20/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 2.3744 - accuracy: 0.2640 - val_loss: 2.3839 - val_accuracy: 0.2732\n",
            "Epoch 21/500\n",
            "132/132 [==============================] - 1s 6ms/step - loss: 2.3435 - accuracy: 0.2716 - val_loss: 2.3566 - val_accuracy: 0.2808\n",
            "Epoch 22/500\n",
            "132/132 [==============================] - 1s 6ms/step - loss: 2.3085 - accuracy: 0.2894 - val_loss: 2.3268 - val_accuracy: 0.2865\n",
            "Epoch 23/500\n",
            "132/132 [==============================] - 1s 6ms/step - loss: 2.2715 - accuracy: 0.3057 - val_loss: 2.2954 - val_accuracy: 0.2960\n",
            "Epoch 24/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 2.2339 - accuracy: 0.3214 - val_loss: 2.2643 - val_accuracy: 0.3074\n",
            "Epoch 25/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 2.1939 - accuracy: 0.3458 - val_loss: 2.2331 - val_accuracy: 0.3226\n",
            "Epoch 26/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 2.1535 - accuracy: 0.3660 - val_loss: 2.1987 - val_accuracy: 0.3491\n",
            "Epoch 27/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 2.1147 - accuracy: 0.3888 - val_loss: 2.1658 - val_accuracy: 0.3719\n",
            "Epoch 28/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 2.0742 - accuracy: 0.4122 - val_loss: 2.1318 - val_accuracy: 0.3890\n",
            "Epoch 29/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 2.0298 - accuracy: 0.4386 - val_loss: 2.0971 - val_accuracy: 0.4042\n",
            "Epoch 30/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 1.9868 - accuracy: 0.4661 - val_loss: 2.0618 - val_accuracy: 0.4288\n",
            "Epoch 31/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 1.9435 - accuracy: 0.4919 - val_loss: 2.0266 - val_accuracy: 0.4421\n",
            "Epoch 32/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 1.8986 - accuracy: 0.5173 - val_loss: 1.9922 - val_accuracy: 0.4801\n",
            "Epoch 33/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 1.8529 - accuracy: 0.5413 - val_loss: 1.9560 - val_accuracy: 0.5009\n",
            "Epoch 34/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 1.8105 - accuracy: 0.5785 - val_loss: 1.9222 - val_accuracy: 0.5351\n",
            "Epoch 35/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 1.7686 - accuracy: 0.5989 - val_loss: 1.8875 - val_accuracy: 0.5541\n",
            "Epoch 36/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 1.7279 - accuracy: 0.6131 - val_loss: 1.8534 - val_accuracy: 0.5750\n",
            "Epoch 37/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 1.6803 - accuracy: 0.6421 - val_loss: 1.8186 - val_accuracy: 0.5939\n",
            "Epoch 38/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 1.6374 - accuracy: 0.6618 - val_loss: 1.7858 - val_accuracy: 0.6243\n",
            "Epoch 39/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 1.5945 - accuracy: 0.6841 - val_loss: 1.7527 - val_accuracy: 0.6471\n",
            "Epoch 40/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 1.5460 - accuracy: 0.7016 - val_loss: 1.7177 - val_accuracy: 0.6490\n",
            "Epoch 41/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 1.5091 - accuracy: 0.7111 - val_loss: 1.6857 - val_accuracy: 0.6641\n",
            "Epoch 42/500\n",
            "132/132 [==============================] - 1s 5ms/step - loss: 1.4721 - accuracy: 0.7222 - val_loss: 1.6546 - val_accuracy: 0.6717\n",
            "Epoch 43/500\n",
            "132/132 [==============================] - 1s 6ms/step - loss: 1.4310 - accuracy: 0.7417 - val_loss: 1.6251 - val_accuracy: 0.6793\n",
            "Epoch 44/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 1.3912 - accuracy: 0.7474 - val_loss: 1.5950 - val_accuracy: 0.6907\n",
            "Epoch 45/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 1.3543 - accuracy: 0.7668 - val_loss: 1.5659 - val_accuracy: 0.6926\n",
            "Epoch 46/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 1.3137 - accuracy: 0.7716 - val_loss: 1.5364 - val_accuracy: 0.7059\n",
            "Epoch 47/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 1.2808 - accuracy: 0.7804 - val_loss: 1.5074 - val_accuracy: 0.7135\n",
            "Epoch 48/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 1.2453 - accuracy: 0.7963 - val_loss: 1.4822 - val_accuracy: 0.7211\n",
            "Epoch 49/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 1.2108 - accuracy: 0.8031 - val_loss: 1.4547 - val_accuracy: 0.7287\n",
            "Epoch 50/500\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 1.1734 - accuracy: 0.8083 - val_loss: 1.4281 - val_accuracy: 0.7324\n",
            "Epoch 51/500\n",
            "132/132 [==============================] - 1s 5ms/step - loss: 1.1416 - accuracy: 0.8131 - val_loss: 1.4023 - val_accuracy: 0.7287\n",
            "Epoch 52/500\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.1112 - accuracy: 0.8162 - val_loss: 1.3796 - val_accuracy: 0.7362\n",
            "Epoch 53/500\n",
            "132/132 [==============================] - 1s 6ms/step - loss: 1.0784 - accuracy: 0.8221 - val_loss: 1.3551 - val_accuracy: 0.7438\n",
            "Epoch 54/500\n",
            "132/132 [==============================] - 1s 6ms/step - loss: 1.0492 - accuracy: 0.8314 - val_loss: 1.3319 - val_accuracy: 0.7476\n",
            "Epoch 55/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 1.0191 - accuracy: 0.8373 - val_loss: 1.3076 - val_accuracy: 0.7476\n",
            "Epoch 56/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.9936 - accuracy: 0.8404 - val_loss: 1.2869 - val_accuracy: 0.7514\n",
            "Epoch 57/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.9642 - accuracy: 0.8432 - val_loss: 1.2669 - val_accuracy: 0.7552\n",
            "Epoch 58/500\n",
            "132/132 [==============================] - 1s 5ms/step - loss: 0.9345 - accuracy: 0.8489 - val_loss: 1.2477 - val_accuracy: 0.7590\n",
            "Epoch 59/500\n",
            "132/132 [==============================] - 1s 5ms/step - loss: 0.9090 - accuracy: 0.8565 - val_loss: 1.2260 - val_accuracy: 0.7590\n",
            "Epoch 60/500\n",
            "132/132 [==============================] - 1s 6ms/step - loss: 0.8861 - accuracy: 0.8605 - val_loss: 1.2090 - val_accuracy: 0.7647\n",
            "Epoch 61/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.8593 - accuracy: 0.8636 - val_loss: 1.1900 - val_accuracy: 0.7647\n",
            "Epoch 62/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.8375 - accuracy: 0.8667 - val_loss: 1.1711 - val_accuracy: 0.7647\n",
            "Epoch 63/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.8129 - accuracy: 0.8712 - val_loss: 1.1555 - val_accuracy: 0.7647\n",
            "Epoch 64/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.7875 - accuracy: 0.8769 - val_loss: 1.1388 - val_accuracy: 0.7666\n",
            "Epoch 65/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.7700 - accuracy: 0.8771 - val_loss: 1.1240 - val_accuracy: 0.7666\n",
            "Epoch 66/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.7474 - accuracy: 0.8814 - val_loss: 1.1100 - val_accuracy: 0.7647\n",
            "Epoch 67/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.7305 - accuracy: 0.8866 - val_loss: 1.0937 - val_accuracy: 0.7685\n",
            "Epoch 68/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.7082 - accuracy: 0.8885 - val_loss: 1.0815 - val_accuracy: 0.7723\n",
            "Epoch 69/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.6913 - accuracy: 0.8933 - val_loss: 1.0666 - val_accuracy: 0.7723\n",
            "Epoch 70/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.6696 - accuracy: 0.8961 - val_loss: 1.0516 - val_accuracy: 0.7742\n",
            "Epoch 71/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.6507 - accuracy: 0.9011 - val_loss: 1.0413 - val_accuracy: 0.7761\n",
            "Epoch 72/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.6382 - accuracy: 0.8982 - val_loss: 1.0277 - val_accuracy: 0.7742\n",
            "Epoch 73/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.6168 - accuracy: 0.9030 - val_loss: 1.0158 - val_accuracy: 0.7856\n",
            "Epoch 74/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.6010 - accuracy: 0.9096 - val_loss: 1.0051 - val_accuracy: 0.7875\n",
            "Epoch 75/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.5845 - accuracy: 0.9115 - val_loss: 0.9946 - val_accuracy: 0.7913\n",
            "Epoch 76/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.5696 - accuracy: 0.9099 - val_loss: 0.9826 - val_accuracy: 0.7894\n",
            "Epoch 77/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.5563 - accuracy: 0.9179 - val_loss: 0.9725 - val_accuracy: 0.7913\n",
            "Epoch 78/500\n",
            "132/132 [==============================] - 1s 5ms/step - loss: 0.5416 - accuracy: 0.9163 - val_loss: 0.9610 - val_accuracy: 0.7913\n",
            "Epoch 79/500\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.5248 - accuracy: 0.9224 - val_loss: 0.9518 - val_accuracy: 0.7970\n",
            "Epoch 80/500\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 0.5129 - accuracy: 0.9248 - val_loss: 0.9430 - val_accuracy: 0.8027\n",
            "Epoch 81/500\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 0.4995 - accuracy: 0.9265 - val_loss: 0.9353 - val_accuracy: 0.8083\n",
            "Epoch 82/500\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 0.4857 - accuracy: 0.9310 - val_loss: 0.9265 - val_accuracy: 0.8027\n",
            "Epoch 83/500\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 0.4726 - accuracy: 0.9312 - val_loss: 0.9161 - val_accuracy: 0.8027\n",
            "Epoch 84/500\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.4622 - accuracy: 0.9357 - val_loss: 0.9084 - val_accuracy: 0.8083\n",
            "Epoch 85/500\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.4496 - accuracy: 0.9357 - val_loss: 0.9012 - val_accuracy: 0.8121\n",
            "Epoch 86/500\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 0.4405 - accuracy: 0.9402 - val_loss: 0.8954 - val_accuracy: 0.8083\n",
            "Epoch 87/500\n",
            "132/132 [==============================] - 1s 6ms/step - loss: 0.4292 - accuracy: 0.9417 - val_loss: 0.8881 - val_accuracy: 0.8065\n",
            "Epoch 88/500\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 0.4176 - accuracy: 0.9400 - val_loss: 0.8812 - val_accuracy: 0.8121\n",
            "Epoch 89/500\n",
            "132/132 [==============================] - 1s 10ms/step - loss: 0.4038 - accuracy: 0.9454 - val_loss: 0.8750 - val_accuracy: 0.8102\n",
            "Epoch 90/500\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.3973 - accuracy: 0.9447 - val_loss: 0.8674 - val_accuracy: 0.8102\n",
            "Epoch 91/500\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.3880 - accuracy: 0.9485 - val_loss: 0.8615 - val_accuracy: 0.8102\n",
            "Epoch 92/500\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.3739 - accuracy: 0.9488 - val_loss: 0.8559 - val_accuracy: 0.8140\n",
            "Epoch 93/500\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 0.3686 - accuracy: 0.9502 - val_loss: 0.8477 - val_accuracy: 0.8140\n",
            "Epoch 94/500\n",
            "132/132 [==============================] - 1s 7ms/step - loss: 0.3580 - accuracy: 0.9540 - val_loss: 0.8414 - val_accuracy: 0.8140\n",
            "Epoch 95/500\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.3507 - accuracy: 0.9528 - val_loss: 0.8375 - val_accuracy: 0.8159\n",
            "Epoch 96/500\n",
            "132/132 [==============================] - 1s 11ms/step - loss: 0.3405 - accuracy: 0.9580 - val_loss: 0.8323 - val_accuracy: 0.8178\n",
            "Epoch 97/500\n",
            "132/132 [==============================] - 1s 10ms/step - loss: 0.3338 - accuracy: 0.9571 - val_loss: 0.8295 - val_accuracy: 0.8140\n",
            "Epoch 98/500\n",
            "132/132 [==============================] - 1s 5ms/step - loss: 0.3241 - accuracy: 0.9620 - val_loss: 0.8241 - val_accuracy: 0.8178\n",
            "Epoch 99/500\n",
            "132/132 [==============================] - 1s 6ms/step - loss: 0.3166 - accuracy: 0.9606 - val_loss: 0.8176 - val_accuracy: 0.8159\n",
            "Epoch 100/500\n",
            "132/132 [==============================] - 2s 15ms/step - loss: 0.3102 - accuracy: 0.9616 - val_loss: 0.8120 - val_accuracy: 0.8178\n",
            "Epoch 101/500\n",
            "132/132 [==============================] - 2s 11ms/step - loss: 0.3011 - accuracy: 0.9642 - val_loss: 0.8083 - val_accuracy: 0.8178\n",
            "Epoch 102/500\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.2933 - accuracy: 0.9647 - val_loss: 0.8033 - val_accuracy: 0.8159\n",
            "Epoch 103/500\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.2865 - accuracy: 0.9639 - val_loss: 0.8003 - val_accuracy: 0.8159\n",
            "Epoch 104/500\n",
            "132/132 [==============================] - 1s 6ms/step - loss: 0.2778 - accuracy: 0.9668 - val_loss: 0.7959 - val_accuracy: 0.8159\n",
            "Epoch 105/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.2709 - accuracy: 0.9677 - val_loss: 0.7917 - val_accuracy: 0.8159\n",
            "Epoch 106/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.2634 - accuracy: 0.9708 - val_loss: 0.7879 - val_accuracy: 0.8159\n",
            "Epoch 107/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.2599 - accuracy: 0.9722 - val_loss: 0.7835 - val_accuracy: 0.8178\n",
            "Epoch 108/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.2506 - accuracy: 0.9722 - val_loss: 0.7810 - val_accuracy: 0.8178\n",
            "Epoch 109/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.2472 - accuracy: 0.9715 - val_loss: 0.7770 - val_accuracy: 0.8197\n",
            "Epoch 110/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.2407 - accuracy: 0.9744 - val_loss: 0.7743 - val_accuracy: 0.8197\n",
            "Epoch 111/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.2323 - accuracy: 0.9756 - val_loss: 0.7743 - val_accuracy: 0.8197\n",
            "Epoch 112/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.2292 - accuracy: 0.9760 - val_loss: 0.7690 - val_accuracy: 0.8197\n",
            "Epoch 113/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.2229 - accuracy: 0.9758 - val_loss: 0.7638 - val_accuracy: 0.8197\n",
            "Epoch 114/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.2171 - accuracy: 0.9772 - val_loss: 0.7604 - val_accuracy: 0.8197\n",
            "Epoch 115/500\n",
            "132/132 [==============================] - 1s 5ms/step - loss: 0.2095 - accuracy: 0.9794 - val_loss: 0.7584 - val_accuracy: 0.8140\n",
            "Epoch 116/500\n",
            "132/132 [==============================] - 1s 6ms/step - loss: 0.2085 - accuracy: 0.9810 - val_loss: 0.7568 - val_accuracy: 0.8197\n",
            "Epoch 117/500\n",
            "132/132 [==============================] - 1s 5ms/step - loss: 0.2003 - accuracy: 0.9806 - val_loss: 0.7554 - val_accuracy: 0.8178\n",
            "Epoch 118/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.1974 - accuracy: 0.9817 - val_loss: 0.7515 - val_accuracy: 0.8178\n",
            "Epoch 119/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.1912 - accuracy: 0.9827 - val_loss: 0.7478 - val_accuracy: 0.8197\n",
            "Epoch 120/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.1886 - accuracy: 0.9832 - val_loss: 0.7476 - val_accuracy: 0.8178\n",
            "Epoch 121/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.1845 - accuracy: 0.9853 - val_loss: 0.7442 - val_accuracy: 0.8235\n",
            "Epoch 122/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.1765 - accuracy: 0.9846 - val_loss: 0.7408 - val_accuracy: 0.8216\n",
            "Epoch 123/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.1741 - accuracy: 0.9853 - val_loss: 0.7388 - val_accuracy: 0.8216\n",
            "Epoch 124/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.1689 - accuracy: 0.9858 - val_loss: 0.7388 - val_accuracy: 0.8178\n",
            "Epoch 125/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.1641 - accuracy: 0.9874 - val_loss: 0.7369 - val_accuracy: 0.8216\n",
            "Epoch 126/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.1611 - accuracy: 0.9870 - val_loss: 0.7342 - val_accuracy: 0.8235\n",
            "Epoch 127/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.1562 - accuracy: 0.9884 - val_loss: 0.7312 - val_accuracy: 0.8235\n",
            "Epoch 128/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.1536 - accuracy: 0.9886 - val_loss: 0.7311 - val_accuracy: 0.8197\n",
            "Epoch 129/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.1518 - accuracy: 0.9872 - val_loss: 0.7270 - val_accuracy: 0.8197\n",
            "Epoch 130/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.1440 - accuracy: 0.9900 - val_loss: 0.7273 - val_accuracy: 0.8235\n",
            "Epoch 131/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.1422 - accuracy: 0.9893 - val_loss: 0.7226 - val_accuracy: 0.8254\n",
            "Epoch 132/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.1370 - accuracy: 0.9900 - val_loss: 0.7223 - val_accuracy: 0.8254\n",
            "Epoch 133/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.1351 - accuracy: 0.9905 - val_loss: 0.7216 - val_accuracy: 0.8254\n",
            "Epoch 134/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.1315 - accuracy: 0.9900 - val_loss: 0.7161 - val_accuracy: 0.8254\n",
            "Epoch 135/500\n",
            "132/132 [==============================] - 1s 5ms/step - loss: 0.1277 - accuracy: 0.9910 - val_loss: 0.7176 - val_accuracy: 0.8235\n",
            "Epoch 136/500\n",
            "132/132 [==============================] - 1s 6ms/step - loss: 0.1238 - accuracy: 0.9926 - val_loss: 0.7173 - val_accuracy: 0.8292\n",
            "Epoch 137/500\n",
            "132/132 [==============================] - 1s 5ms/step - loss: 0.1211 - accuracy: 0.9917 - val_loss: 0.7138 - val_accuracy: 0.8273\n",
            "Epoch 138/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.1169 - accuracy: 0.9919 - val_loss: 0.7165 - val_accuracy: 0.8273\n",
            "Epoch 139/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.1168 - accuracy: 0.9922 - val_loss: 0.7141 - val_accuracy: 0.8273\n",
            "Epoch 140/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.1103 - accuracy: 0.9936 - val_loss: 0.7142 - val_accuracy: 0.8273\n",
            "Epoch 141/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.1081 - accuracy: 0.9941 - val_loss: 0.7120 - val_accuracy: 0.8292\n",
            "Epoch 142/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.1066 - accuracy: 0.9929 - val_loss: 0.7091 - val_accuracy: 0.8311\n",
            "Epoch 143/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.1047 - accuracy: 0.9936 - val_loss: 0.7077 - val_accuracy: 0.8330\n",
            "Epoch 144/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.1013 - accuracy: 0.9936 - val_loss: 0.7076 - val_accuracy: 0.8273\n",
            "Epoch 145/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0984 - accuracy: 0.9922 - val_loss: 0.7063 - val_accuracy: 0.8311\n",
            "Epoch 146/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0950 - accuracy: 0.9950 - val_loss: 0.7061 - val_accuracy: 0.8330\n",
            "Epoch 147/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0938 - accuracy: 0.9936 - val_loss: 0.7048 - val_accuracy: 0.8292\n",
            "Epoch 148/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0907 - accuracy: 0.9943 - val_loss: 0.7039 - val_accuracy: 0.8311\n",
            "Epoch 149/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0888 - accuracy: 0.9950 - val_loss: 0.7047 - val_accuracy: 0.8292\n",
            "Epoch 150/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0860 - accuracy: 0.9953 - val_loss: 0.7032 - val_accuracy: 0.8273\n",
            "Epoch 151/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0856 - accuracy: 0.9941 - val_loss: 0.7035 - val_accuracy: 0.8330\n",
            "Epoch 152/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0837 - accuracy: 0.9950 - val_loss: 0.7009 - val_accuracy: 0.8311\n",
            "Epoch 153/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0788 - accuracy: 0.9969 - val_loss: 0.7016 - val_accuracy: 0.8311\n",
            "Epoch 154/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0776 - accuracy: 0.9964 - val_loss: 0.7011 - val_accuracy: 0.8330\n",
            "Epoch 155/500\n",
            "132/132 [==============================] - 1s 6ms/step - loss: 0.0768 - accuracy: 0.9969 - val_loss: 0.7005 - val_accuracy: 0.8330\n",
            "Epoch 156/500\n",
            "132/132 [==============================] - 1s 6ms/step - loss: 0.0759 - accuracy: 0.9943 - val_loss: 0.6980 - val_accuracy: 0.8330\n",
            "Epoch 157/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0731 - accuracy: 0.9964 - val_loss: 0.6973 - val_accuracy: 0.8330\n",
            "Epoch 158/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0702 - accuracy: 0.9962 - val_loss: 0.6975 - val_accuracy: 0.8292\n",
            "Epoch 159/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0681 - accuracy: 0.9969 - val_loss: 0.6968 - val_accuracy: 0.8311\n",
            "Epoch 160/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0681 - accuracy: 0.9967 - val_loss: 0.6964 - val_accuracy: 0.8292\n",
            "Epoch 161/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0632 - accuracy: 0.9964 - val_loss: 0.6965 - val_accuracy: 0.8330\n",
            "Epoch 162/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0628 - accuracy: 0.9969 - val_loss: 0.6973 - val_accuracy: 0.8311\n",
            "Epoch 163/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0621 - accuracy: 0.9953 - val_loss: 0.6978 - val_accuracy: 0.8292\n",
            "Epoch 164/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0615 - accuracy: 0.9974 - val_loss: 0.6925 - val_accuracy: 0.8330\n",
            "Epoch 165/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0574 - accuracy: 0.9974 - val_loss: 0.6948 - val_accuracy: 0.8330\n",
            "Epoch 166/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0588 - accuracy: 0.9979 - val_loss: 0.6974 - val_accuracy: 0.8292\n",
            "Epoch 167/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0566 - accuracy: 0.9979 - val_loss: 0.6936 - val_accuracy: 0.8349\n",
            "Epoch 168/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0544 - accuracy: 0.9979 - val_loss: 0.6902 - val_accuracy: 0.8349\n",
            "Epoch 169/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0535 - accuracy: 0.9972 - val_loss: 0.6921 - val_accuracy: 0.8349\n",
            "Epoch 170/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0518 - accuracy: 0.9988 - val_loss: 0.6909 - val_accuracy: 0.8311\n",
            "Epoch 171/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0487 - accuracy: 0.9986 - val_loss: 0.6959 - val_accuracy: 0.8311\n",
            "Epoch 172/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0491 - accuracy: 0.9976 - val_loss: 0.6942 - val_accuracy: 0.8349\n",
            "Epoch 173/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0473 - accuracy: 0.9986 - val_loss: 0.6938 - val_accuracy: 0.8387\n",
            "Epoch 174/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0466 - accuracy: 0.9983 - val_loss: 0.6946 - val_accuracy: 0.8311\n",
            "Epoch 175/500\n",
            "132/132 [==============================] - 1s 6ms/step - loss: 0.0470 - accuracy: 0.9995 - val_loss: 0.6897 - val_accuracy: 0.8444\n",
            "Epoch 176/500\n",
            "132/132 [==============================] - 1s 6ms/step - loss: 0.0447 - accuracy: 0.9981 - val_loss: 0.6930 - val_accuracy: 0.8368\n",
            "Epoch 177/500\n",
            "132/132 [==============================] - 1s 5ms/step - loss: 0.0420 - accuracy: 0.9981 - val_loss: 0.6924 - val_accuracy: 0.8349\n",
            "Epoch 178/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0419 - accuracy: 0.9979 - val_loss: 0.6948 - val_accuracy: 0.8311\n",
            "Epoch 179/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0410 - accuracy: 0.9991 - val_loss: 0.6940 - val_accuracy: 0.8368\n",
            "Epoch 180/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0408 - accuracy: 0.9974 - val_loss: 0.6937 - val_accuracy: 0.8368\n",
            "Epoch 181/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0401 - accuracy: 0.9983 - val_loss: 0.6939 - val_accuracy: 0.8387\n",
            "Epoch 182/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0370 - accuracy: 0.9991 - val_loss: 0.6914 - val_accuracy: 0.8406\n",
            "Epoch 183/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0366 - accuracy: 0.9991 - val_loss: 0.6980 - val_accuracy: 0.8368\n",
            "Epoch 184/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0353 - accuracy: 0.9993 - val_loss: 0.6941 - val_accuracy: 0.8368\n",
            "Epoch 185/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0339 - accuracy: 0.9993 - val_loss: 0.6932 - val_accuracy: 0.8406\n",
            "Epoch 186/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0342 - accuracy: 0.9993 - val_loss: 0.6927 - val_accuracy: 0.8330\n",
            "Epoch 187/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0332 - accuracy: 0.9993 - val_loss: 0.6955 - val_accuracy: 0.8406\n",
            "Epoch 188/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0319 - accuracy: 1.0000 - val_loss: 0.6958 - val_accuracy: 0.8406\n",
            "Epoch 189/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0311 - accuracy: 0.9993 - val_loss: 0.6945 - val_accuracy: 0.8387\n",
            "Epoch 190/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0311 - accuracy: 0.9993 - val_loss: 0.6980 - val_accuracy: 0.8368\n",
            "Epoch 191/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0289 - accuracy: 0.9995 - val_loss: 0.6960 - val_accuracy: 0.8406\n",
            "Epoch 192/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0291 - accuracy: 0.9988 - val_loss: 0.6981 - val_accuracy: 0.8387\n",
            "Epoch 193/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0280 - accuracy: 0.9995 - val_loss: 0.6929 - val_accuracy: 0.8425\n",
            "Epoch 194/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0284 - accuracy: 0.9995 - val_loss: 0.6936 - val_accuracy: 0.8387\n",
            "Epoch 195/500\n",
            "132/132 [==============================] - 1s 5ms/step - loss: 0.0275 - accuracy: 0.9998 - val_loss: 0.6953 - val_accuracy: 0.8425\n",
            "Epoch 196/500\n",
            "132/132 [==============================] - 1s 6ms/step - loss: 0.0267 - accuracy: 0.9993 - val_loss: 0.6943 - val_accuracy: 0.8444\n",
            "Epoch 197/500\n",
            "132/132 [==============================] - 1s 5ms/step - loss: 0.0272 - accuracy: 0.9988 - val_loss: 0.6939 - val_accuracy: 0.8463\n",
            "Epoch 198/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0252 - accuracy: 0.9995 - val_loss: 0.6976 - val_accuracy: 0.8425\n",
            "Epoch 199/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0238 - accuracy: 0.9998 - val_loss: 0.6985 - val_accuracy: 0.8406\n",
            "Epoch 200/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0247 - accuracy: 0.9993 - val_loss: 0.6985 - val_accuracy: 0.8406\n",
            "Epoch 201/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0229 - accuracy: 0.9998 - val_loss: 0.7003 - val_accuracy: 0.8387\n",
            "Epoch 202/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0234 - accuracy: 0.9995 - val_loss: 0.6978 - val_accuracy: 0.8406\n",
            "Epoch 203/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0212 - accuracy: 0.9998 - val_loss: 0.6987 - val_accuracy: 0.8406\n",
            "Epoch 204/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0220 - accuracy: 0.9995 - val_loss: 0.6999 - val_accuracy: 0.8444\n",
            "Epoch 205/500\n",
            "132/132 [==============================] - 1s 4ms/step - loss: 0.0211 - accuracy: 0.9995 - val_loss: 0.6994 - val_accuracy: 0.8444\n",
            "Epoch 205: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# printing loss and accuracy of the model on the test set\n",
        "loss, accuracy = model.evaluate(test_ds)\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FksY9EwwHDkd",
        "outputId": "95743bb1-112a-48d4-bf76-50c5dacc9f17"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17/17 [==============================] - 0s 3ms/step - loss: 0.8237 - accuracy: 0.8330\n",
            "Loss:  0.8236562609672546\n",
            "Accuracy:  0.8330170512199402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting the history of training and its keys\n",
        "history_dict = history.history\n",
        "history_dict.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPdyDruxHIv1",
        "outputId": "2d987cf6-8da0-4856-820b-0382a610c269"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history_dict['accuracy']\n",
        "val_acc = history_dict['val_accuracy']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)"
      ],
      "metadata": {
        "id": "shbF_xRlHDqZ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ploting of loss\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "iLsoTgHGP7Oq",
        "outputId": "46865251-6c3e-43bb-d9e5-dd371ae1a4c5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting of accuracy\n",
        "plt.plot(epochs, acc, 'b', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "1uWqq-CtP-Lq",
        "outputId": "410496b8-a889-4fb0-8b64-51850add9d09"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating the probability model for testing\n",
        "probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n",
        "\n",
        "# predicting test samples\n",
        "predictions = probability_model.predict(raw_test_batch.map(vectorize_text))"
      ],
      "metadata": {
        "id": "YQj61lIMvX-Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "448f79dc-f069-49e4-ce4f-380514858f88"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17/17 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# showing the first test sample result label\n",
        "np.argmax(predictions[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cbhBKR7NYPQ",
        "outputId": "813e48e2-fd20-4409-a50a-4930e4e35c2b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# showing the true label of the first test sample\n",
        "test_df.iloc[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNsnTWVuu3xj",
        "outputId": "91b96764-cc72-45d9-df78-d9504d7cec1b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text         herschel sulfur spring olive night reflective ...\n",
              "label                                           Luggage & Bags\n",
              "label_int                                                   12\n",
              "Name: 3686, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bOt2UPu7NbUW"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Author:** https://farrokhkarimi.github.io/"
      ],
      "metadata": {
        "id": "CSw7kwIQipyc"
      }
    }
  ]
}